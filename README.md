# ğŸ“˜ Introduction

This is a lightweight hybrid model of CNN and Transformer, which only have 600k parameters and achieves 93.1% accuracy on Fasion Mnist Dataset. 

---

## ğŸ“ ç›®å½•

- [Introduction](#Introduction)
- [åŠŸèƒ½ç‰¹ç‚¹](#åŠŸèƒ½ç‰¹ç‚¹)
- [å®‰è£…æ–¹æ³•](#å®‰è£…æ–¹æ³•)
- [ä½¿ç”¨æ–¹æ³•](#ä½¿ç”¨æ–¹æ³•)
- [é¡¹ç›®ç»“æ„](#é¡¹ç›®ç»“æ„)
- [æ¨¡å‹è®­ç»ƒ / æ•°æ®ä½¿ç”¨ï¼ˆå¯é€‰ï¼‰](#æ¨¡å‹è®­ç»ƒ--æ•°æ®ä½¿ç”¨å¯é€‰)
- [è´¡çŒ®æ–¹å¼](#è´¡çŒ®æ–¹å¼)
- [è®¸å¯è¯](#è®¸å¯è¯)
- [è‡´è°¢](#è‡´è°¢)

---

## ğŸ“– Project Introduction

Fashion-MNIST is a dataset of Zalando's article images, consisting of 60,000 training examples and 10,000 test examples. Each example is a 28x28 grayscale image associated with one of 10 fashion categories.

This project builds a hybrid model combining CNN and Transformer architectures. Specifically, the CNN is used to extract local features, followed by a Transformer to capture global features. The model contains only about 600k parameters, making it lightweight and suitable for training on most devices. After 90 epochs of training, it achieves an impressive accuracy of 93.1%.

Finally, Grad-CAM is used to visualize and interpret the modelâ€™s decision-making process by highlighting the important regions in the input image that influence predictions.


---

## âœ¨ åŠŸèƒ½ç‰¹ç‚¹

- âœ… æ•°æ®é¢„å¤„ç†ä¸åŠ è½½  
- âœ… æ¨¡å‹è®­ç»ƒä¸éªŒè¯  
- âœ… Grad-CAM å¯è§†åŒ–  
- âœ… æ”¯æŒ CLI å‚æ•°é…ç½®  
- âœ… æ”¯æŒ CPU/GPU  

---

## ğŸ› ï¸ å®‰è£…æ–¹æ³•

```bash
git clone https://github.com/James-sjt/FashionMnist.git
cd FashionMnist
